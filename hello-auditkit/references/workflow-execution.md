# 审计工作流程执行指南

> **何时读取**：执行完整审计且需要逐步指导时。
> **前提条件**：先阅读 SKILL.md 了解核心原则和约束。

## 目录

- [步骤 1：获取最新提示词指南](#步骤-1获取最新提示词指南)
- [步骤 2：检测与分类](#步骤-2检测与分类)
- [步骤 2B：规则加载验证](#步骤-2b规则加载验证必须)
- [步骤 3：执行通用检查](#步骤-3执行通用检查)
- [步骤 3B：执行证据检查点](#步骤-3b执行证据检查点必须)
- [步骤 4：执行类型特定检查](#步骤-4执行类型特定检查)
- [步骤 5：执行交叉检查](#步骤-5执行交叉检查)
- [步骤 6：问题验证](#步骤-6问题验证)
- [步骤 7：修复建议验证](#步骤-7修复建议验证)
- [步骤 7B：引用回查验证](#步骤-7b引用回查验证强制)
- [步骤 8：生成报告](#步骤-8生成报告)
- [步骤 8B：保存报告到文件](#步骤-8b保存报告到文件必须)
- [步骤 9：等待用户确认](#步骤-9等待用户确认)

---

## 步骤 1：获取最新提示词指南（必须标准）

> **关键**：GPT 提示词指南是**主要审计标准**，不仅仅是参考。所有提示词/指令必须根据这些规则进行评估。

1. 访问此目录页获取文件列表：`https://github.com/openai/openai-cookbook/tree/main/examples/gpt-5`
2. 选择最新版本的提示词指南（如 `gpt-5-2_prompting_guide.ipynb` > `gpt-5-1_prompting_guide.ipynb` > `gpt-5_prompting_guide.ipynb`）
3. 从指南中提取并应用这些**必须检查项**：
   - **详尽约束**："≤N 句/要点/字" 存在吗？
   - **范围纪律**："完全且仅限所请求内容" + "禁止"列表存在吗？
   - **停止条件**：多阶段内容有明确的完成标准吗？
   - **禁止捏造**：事实性任务有"禁止捏造..."指令吗？
   - **长上下文处理**：>10k token 有大纲 + 约束重述吗？
   - **工具偏好**：获取新鲜数据时优先使用工具而非内部知识？
   - **代理式更新**：仅在主要阶段简短（1-2 句）？
   - **结构化标签块**：角括号标签包裹关键约束？
4. **结构化标签块检查**：
   - 识别提示词类型：代理式、提取、事实性、工具使用、长上下文、高风险
   - 检查角括号标签是否按类型包裹相关约束（见 SKILL.md 原则 0 表格）
   - 标签名称可自定义 - 检查结构存在性和语义正确性
   - 如果复杂提示词缺少标签 → 标记为 Warning/Info（不是 Severe）
5. 与 `type-prompt.md` 中的内置检查交叉验证
6. 如果被审计内容违反以上任何必须检查项 → **标记为 Severe**

**证据输出**：记录获取的指南版本，列出应用的必须检查项（包括结构化标签），记录发现的任何违规。

**如果指南链接无法访问或获取的内容不可用**（如被阻止、限流、空/部分内容、解析失败、或无法提取所需规则）：回退到离线模式前先重试。如果仍然失败，使用本技能的内置规则审计（至少 `type-prompt.md` + `rules-universal.md`），并在报告中注明 `离线模式 - [原因]`（第 2 节 → GPT 指南合规性）。

---

## 步骤 2：检测与分类

扫描路径 → 识别类型 → 加载适当规则：

```
任意文本/文件   → type-prompt.md（未识别类型的默认）
记忆文件       → type-memory.md（AGENTS.md, CLAUDE.md, GEMINI.md）
技能          → type-skill.md（包含 SKILL.md 的目录）
插件          → type-plugin.md（包含 .claude-plugin/ 的目录）
复合          → 应用全部 + cross-*.md
```

---

## 步骤 2B：规则加载验证（必须）

<rule_loading_verification>
**关键**：检测内容类型后，根据下方"验证清单"验证所有必需规则文件已加载。

**执行**：
1. 从步骤 2 识别内容类型
2. 查阅下方验证清单
3. 加载该内容类型所有必需文件
4. 检查条件文件（⚡）：扫描内容查找触发器（规则/列表、阶段、命令、工具）
5. 如找到触发器则加载条件文件
6. **输出**："已加载：[文件列表]。条件：[因 X 触发器加载的文件]。"

**验证清单**：
| 内容类型 | 最少需加载文件 | 验证已加载 |
|----------|---------------|-----------|
| Prompt | 3 文件：rules-universal、type-prompt、ref-gpt-prompting-standard | ☐ |
| Memory | 3 文件：rules-universal、type-memory、ref-gpt-prompting-standard | ☐ |
| Skill | 7 文件：rules-universal、rules-structure-integrity、type-skill、cross-progressive-loading、cross-design-coherence、ref-gpt-prompting-standard、ref-codex-skills-standard | ☐ |
| Plugin | 9 文件：rules-universal、rules-structure-integrity、rules-runtime-behavior、type-plugin、cross-progressive-loading、cross-design-coherence、cross-composite、ref-gpt-prompting-standard、ref-codex-skills-standard | ☐ |
| Composite | 全部 17 个参考文件 | ☐ |

**如有任何必需文件未加载 → 停止并在继续前加载。**
</rule_loading_verification>

---

## 步骤 3：执行通用检查（所有类型）

> **首先**：在继续之前先执行原则 0（GPT 指南合规性）检查。
> **核心原则来源**：`methodology-core.md` 定义了问题验证（步骤 6）和修复验证（步骤 7）中使用的五点验证、奥卡姆剃刀、AI 能力模型和尺寸容忍阈值。

**GPT 指南合规性检查（必须首先）：**

执行 SKILL.md 原则 0 表格中的每项检查，记录状态和证据（行号、引用）。

**每次审计必须执行 `rules-universal.md` 中的这些检查：**

| 类别 | 所需操作 | 证据输出 |
|------|---------|----------|
| 命名与编号 | 提取所有：(1) 命名约定（kebab-case、无特殊字符），(2) 编号序列 → 验证连续、无重复、无缺口，(3) 顺序验证 → 章节顺序逻辑、标题层次 H1→H2→H3 | "检查了 N 个序列，M 个命名问题，K 个顺序问题" |
| 引用完整性 | 提取所有引用（文件引用、锚点链接、编号引用如 R1/步骤 2）→ 验证每个目标存在、无循环引用 | "检查了 N 个引用，M 个断链，K 个循环" |
| 结构与组织 | (1) 目录-内容匹配，(2) 章节分类正确，(3) 模板合规（必需章节存在、顺序正确），(4) 无孤立章节 | "目录：N 条目 vs M 标题，K 不匹配；模板：L 问题" |
| 图表与流程图 | 如存在：(1) 节点-文本一致性，(2) 所有路径有端点，(3) 无无限循环，(4) 决策分支完整 | "检查了 N 个图表，M 个一致性问题，K 个逻辑问题" |
| 语言表达 | (1) 歧义模式（无条件的 may/might/could），(2) 术语一致性（同概念=同术语），(3) 标识符/标题拼写错误，(4) 冗余内容，(5) LLM 措辞模式（含糊语言、避免绝对、范围约束措辞、详尽约束措辞） | "发现 N 歧义、M 术语、K 拼写、L 冗余、P 措辞问题" |
| 安全与合规 | 检查硬编码的秘密、路径、凭据；输入验证规则 | "已检查，N 个安全问题" |
| 尺寸阈值 | SKILL.md 正文：应用分层阈值（≤500 理想）。参考文件：按内容性质评估 | "SKILL.md：N 行（状态）" |
| 规则逻辑 | 如存在规则：(1) 无冲突，(2) 无重复/语义等价，(3) 覆盖完整，(4) 优化机会（DELETE > MERGE > MODIFY） | "检查了 N 条规则：M 冲突、K 重复、L 缺口" |
| 流程逻辑 | 如定义了流程/流：(1) 覆盖所有场景，(2) 主流程清晰，(3) 无死循环，(4) 无冲突调用 | "流程：N 场景，M 流问题" |
| **结构完整性** | 如基于规则的内容：(1) 文件结构完整，(2) 规则命名一致，(3) 编号连续，(4) 顺序逻辑，(5) 层次正确，(6) 无重复，(7) 引用有效，(8) 规则有效，(9) 规则合理 | "结构：N 文件、M 命名、K 编号、L 顺序、P 层次、Q 重复、R 引用、S 有效性、T 合理性问题" |
| 输出与国际化 | 如定义了输出格式：(1) 格式规范完整，(2) 语言控制正确（如配置了国际化），(3) 无硬编码的语言特定内容 | "输出：N 格式问题，M 国际化问题" |
| Prompt 合规性 | (1) 详尽约束存在，(2) 范围边界带"禁止"列表，(3) 禁止捏造指令，(4) 结构化任务有输出模式，(5) 不确定声明有接地，(6) 工具优先于内部知识，(7) 代理式更新简短带具体结果，(8) >10k token 有长上下文大纲，(9) 复杂提示词有**结构化标签块** | "Prompt：N 详尽、M 范围、K 接地、L 工具、P 代理式、Q 结构问题" |
| 对话式/多阶段 | 如内容有阶段：(1) 约束在顶部，(2) 明确停止条件，(3) 范围漂移预防，(4) 阶段门，(5) **约束集中**（规则在 ≤3 处），(6) **停止条件强度**（强 vs 弱），(7) **禁止语言强度**（"禁止/Do NOT" vs "不要/don't"） | "对话式：N 问题（集中：X，停止强度：Y，禁止：Z）" |
| **推理标签** | 如内容有复杂决策点：(1) 关键判断处有推理标签，(2) 标签内容仅是推理（无执行步骤），(3) 标签正确闭合，(4) 标签名称遵循 `<{领域}_{动作}>` 约定 | "推理标签：N 决策点，M 已标记，K 内容问题" |
| **运行时行为** | 执行 `rules-runtime-behavior.md` 中的检查：(1) 术语准确性**（通用）**，(2) 冲突检测**（通用）**，(3) 路由规则**（如有调度逻辑）**，(4) 阶段触发器/流程/输出**（如多阶段）**，(5) 命令触发器/流程/输出**（如 CLI/命令）**，(6) 外部工具触发器/流程/输出**（如工具调用）**，(7) 渐进加载**（如 Skill/Plugin）** | "运行时：术语 OK，N 冲突；条件检查按适用情况" |
| **AI 执行者意识** | (1) 检查过度指定（指定 AI 能推断的），(2) 避免对 AI 已知概念的冗余解释，(3) 应用 30% 阈值测试：如 <30% 会误解 → 不是问题 | "AI 意识：N 过度指定，M 冗余解释" |
| **格式规则** | (1) Frontmatter 验证（必需字段、YAML 语法），(2) Markdown 结构（标题层次 H1→H2→H3），(3) 命名约定（kebab-case、无空格/特殊字符），(4) 文件编码（UTF-8 无 BOM） | "格式：N frontmatter、M markdown、K 命名问题" |

**编号检查执行**（常被遗漏）：
1. 找到所有编号列表（1. 2. 3. 或 步骤 0、步骤 1 等）
2. 验证：连续？无重复？无缺口？
3. 找到所有目录条目 → 验证每个有对应标题
4. 跨章节：如步骤跨章节（步骤 0 在这里，步骤 3 在那里），验证连续性

---

## 步骤 3B：执行证据检查点（必须）

<execution_evidence_checkpoint>
**关键**：在继续步骤 4 之前，必须输出执行证据矩阵，显示实际执行了哪些检查。这防止"审计漂移"——加载了检查但未执行。

**必须输出格式**：

```
## 执行证据（步骤 3）

| 类别 | 已执行 | 证据 | 发现问题 |
|------|--------|------|----------|
| GPT 指南合规性 | ✅/❌ | [行号引用或"不适用"] | N |
| 命名与编号 | ✅/❌ | "检查了 N 个序列" | N |
| 引用完整性 | ✅/❌ | "检查了 N 个引用" | N |
| 结构与组织 | ✅/❌ | "目录：X vs Y" | N |
| 语言表达 | ✅/❌ | "发现 N 个模式" | N |
| 安全与合规 | ✅/❌ | "已检查" | N |
| 尺寸阈值 | ✅/❌ | "N 行" | N |
| [其他适用类别...] | | | |

**跳过（附原因）**：[列出跳过的类别及原因]
```

**规则**：
1. 每个标记 ✅ 的类别必须有非空的证据列
2. 每个标记 ❌ 的类别必须有跳过原因
3. 如果类别适用但未执行 → 这是审计失败，返回执行
4. "不适用"仅对真正不适用的类别有效（如无图表时的图表检查）

**必须执行的核心类别**（任何内容类型都不能跳过）：
- GPT 指南合规性（原则 0）
- 命名与编号
- 引用完整性
- 语言表达
- 尺寸阈值

**条件类别**（仅在条件不满足时跳过）：
- 图表与流程图 → 如无图表则跳过
- 安全与合规 → 如无脚本/路径/凭据则跳过
- 结构完整性 → 如非基于规则的内容则跳过
- 运行时行为 → 如无运行时逻辑则跳过

**如未输出执行证据 → 不要继续步骤 4。**
</execution_evidence_checkpoint>

---

## 步骤 4：执行类型特定检查

**根据内容类型，执行相关文件中的所有检查：**

### 对于 Prompt（`type-prompt.md`）：

> **主要标准**：`ref-gpt-prompting-standard.md`（GPT-5.2 提示词指南）

| 检查类别 | 操作 |
|----------|------|
| 加载 GPT-5.2 标准 | 读取 `ref-gpt-prompting-standard.md`，应用所有约束检查 |
| 结构验证 | 有详尽约束？范围边界？输出格式？ |
| 内容质量 | 指令具体？不模糊？ |
| LLM 最佳实践 | 自由度匹配？接地？歧义处理？ |
| Prompt 合规性 | 详尽限制？"禁止"列表？禁止捏造？模式？自检？ |
| **结构化标签块** | 详尽性有角括号标签？范围？提取？更新？ |
| 对话式/多阶段 | 如有阶段：约束在顶部？停止条件（强）？范围漂移预防？阶段门？**约束集中？** **禁止语言强度？** |
| 审计清单 | 执行 `ref-gpt-prompting-standard.md` 中所有 Fatal/Severe/Warning 检查 |

### 对于记忆文件（`type-memory.md`）：

> **主要标准**：`ref-gpt-prompting-standard.md`（用于指令内容）

| 检查类别 | 操作 |
|----------|------|
| 结构验证 | 文件位置？合并层次？ |
| 导入语法 | 有效的 `@path` 导入？ |
| 内容质量 | 具体？可操作？不模糊？ |
| 指令质量 | 应用 GPT-5.2 检查：详尽约束？范围边界？ |

### 对于技能（`type-skill.md`）：

> **主要标准**：`ref-codex-skills-standard.md`（Codex CLI Skills 规范）
> **次要标准**：`ref-gpt-prompting-standard.md`（用于 SKILL.md 正文内容）

| 检查类别 | 操作 |
|----------|------|
| 加载 Codex Skills 标准 | 读取 `ref-codex-skills-standard.md`，应用所有结构/frontmatter 检查 |
| 目录验证 | SKILL.md 存在？文件名正确？目录名匹配 `name` 字段？ |
| Frontmatter（按 Codex 规范）| `name`：≤64 字符、小写+连字符、不以 `-` 开头/结尾、无 `--`、匹配目录 |
| Frontmatter（按 Codex 规范）| `description`：≤1024 字符、有触发条件 |
| Frontmatter（可选）| `license`、`compatibility`（≤500 字符）、`metadata`、`allowed-tools` |
| 正文大小 | SKILL.md：≤500 理想，>625 警告。参考文件：无限制，按内容评估 |
| 正文内容 | 应用 `ref-gpt-prompting-standard.md` 中的 GPT-5.2 检查 |
| 脚本完整性 | 声明的脚本存在？导入有效？Shebang？错误处理？ |
| 参考文件 | 有"何时读取"指导？ |
| 渐进加载 | L1 ≤100 词？L2 ≤500 行？核心在 L2？ |
| 对话式/多阶段 | 如正文有阶段：应用 `ref-gpt-prompting-standard.md` 中的检查 |

### 对于插件（`type-plugin.md`）：

> **主要标准**：`ref-codex-skills-standard.md`（用于插件内的技能）
> **次要标准**：`ref-gpt-prompting-standard.md`（用于命令/代理正文）

| 检查类别 | 操作 |
|----------|------|
| 结构 | plugin.json 在 .claude-plugin/ 内？组件在根目录？ |
| 路径变量 | 使用相对路径或环境变量？无硬编码绝对路径？ |
| 命令 | 有效的 frontmatter？allowed-tools 有效？正文：应用 GPT-5.2 检查 |
| 代理 | name、description、tools 有效？正文：应用 GPT-5.2 检查 |
| 插件内的技能 | 应用 `ref-codex-skills-standard.md` 中的完整 Codex Skills 标准 |
| 钩子 | 包装器格式？有效的匹配器？脚本存在？ |
| MCP/LSP | 有效的 JSON？路径正确？无硬编码秘密？ |

---

## 步骤 5：执行交叉检查（多文件系统）

**对于技能、插件、复合，执行以下所有检查：**

### 来自 `cross-design-coherence.md`：

| 检查 | 操作 |
|------|------|
| 完整目录扫描 | 枚举所有文件，分类每个，构建规则清单 |
| 设计哲学 | 从所有文件提取原则，检查一致性 |
| 规则传播 | 全局规则在本地文件中应用？ |
| 冲突检测 | 同文件内矛盾？跨文件矛盾？ |
| 结构冗余 | 重复章节？重复表格？平行内容？→ 集中化 |
| 危险信号 | SKILL.md >625 行？规则分散（>3 文件）？循环依赖？ |

### 来自 `cross-progressive-loading.md`：

| 检查 | 操作 |
|------|------|
| 内容层级审计 | L1 ≤100 词？L2 ≤500 行？L3：按内容性质评估 |
| 内容放置 | 核心工作流在 L2？边缘情况在 L3？ |
| 参考文件指导 | 每个参考文件有"何时读取"？ |
| 反模式 | 元数据膨胀？单体正文？核心在 L3？ |

### 来自 `cross-composite.md`：

| 检查 | 操作 |
|------|------|
| 引用完整性 | 所有跨文件引用有效？ |
| 术语一致性 | 跨文件同概念=同术语？ |
| 编号一致性 | 跨所有文件连续？无重复？ |
| 脚本完整性 | 所有声明的脚本存在？导入有效？ |

---

## 步骤 6：问题验证（五点检查）

> **权威来源**：`methodology-core.md` → 五点验证

<issue_verification_reasoning>
五点验证是核心判断过程。每个疑似问题需要深度推理：
1. 具体场景：能描述一个具体的失败场景吗？
2. 设计范围：在预期设计边界内吗？
3. 功能能力：实现与声称的能力匹配吗？
4. 缺陷 vs 选择：是无意错误还是有效的设计选择？
5. 达到阈值：超过量化阈值吗？
如果任何一点失败 → 丢弃该问题
</issue_verification_reasoning>

对每个疑似问题，验证所有点：
1. **具体场景** - 能描述具体失败？
2. **设计范围** - 在预期边界内？
3. **功能能力** - 实现与声称的能力匹配？
4. **缺陷 vs 选择** - 无意错误还是有效设计？
5. **达到阈值** - 超过量化阈值？

如果任何一点失败 → 丢弃该问题（移至已过滤）

**对于"缺失/不完整"问题**：确认前完整重读源内容。ASCII 图表在首次扫描时容易解析错误。

---

## 步骤 7：修复建议验证（原则检查）

**关键**：在输出任何修复建议之前，根据核心原则验证并应用正确的标准。

<fix_validation_comparison>
修复建议验证需要跨多个维度比较：
- 奥卡姆剃刀：这个添加真的必要吗？DELETE/MERGE/MODIFY 能否替代 ADD？
- AI 推断：AI 能从现有示例/上下文/模式推断正确行为吗？
- 硬编码检查：这是否在 AI 应从上下文判断的地方添加硬编码值（如"≤5 项"）？
- 禁止检查：这是否在添加 AI 已从意图/上下文理解的"禁止"规则？
- 示例冗余：原始设计是否已通过示例/结构传达意图？
- 标准合规：修复是否符合适用标准（GPT-5.2 或 Codex Skills）？
</fix_validation_comparison>

### 修复标准选择

| 内容类型 | 修复标准 | 参考文件 |
|----------|----------|----------|
| Prompt/指令文本 | GPT-5.2 提示词指南 | `ref-gpt-prompting-standard.md` |
| Skill 结构/frontmatter | Codex CLI Skills 规范 | `ref-codex-skills-standard.md` |
| Skill 正文内容 | 两个标准 | 两个文件 |
| Plugin 结构 | Codex CLI Skills 规范 | `ref-codex-skills-standard.md` |
| 命令/代理正文 | GPT-5.2 提示词指南 | `ref-gpt-prompting-standard.md` |

### 原则验证

| 检查 | 问题 | 如果否 → |
|------|------|----------|
| 奥卡姆剃刀 | 这个添加真的必要吗？目标能否通过 DELETE/MERGE/MODIFY 而非 ADD 达成？ | 重新考虑修复方法 |
| AI 推断 | AI 能从现有示例/上下文/模式推断正确行为吗？ | 不要添加显式规则 |
| 硬编码检查 | 这是否在 AI 应根据上下文判断的地方添加硬编码值（如"≤5 要点"、"≤200 字"）？ | 移除硬编码值 |
| 禁止检查 | 这是否在 AI 已从意图/上下文理解的地方添加"禁止"规则？ | 移除不必要的禁止 |
| 示例冗余 | 原始设计是否已通过示例/结构传达意图？ | 不要添加冗余规则 |
| **标准合规** | 修复是否符合适用标准（GPT-5.2 或 Codex Skills）？ | 修改以匹配标准 |

### 修复内容指南

**对于 GPT-5.2 标准修复**（文本内容）：
- 如缺失则添加详尽约束："≤N 句/要点"
- 如缺失则添加范围约束："禁止添加/扩展/捏造..."
- 如是复杂提示词则添加结构化标签
- 关键约束使用强禁止语言
- 约束集中在顶部

**对于 Codex Skills 标准修复**（技能结构）：
- 修复 `name` 字段：小写、仅连字符、≤64 字符、匹配目录
- 修复 `description`：≤1024 字符、包含触发条件
- 修复目录结构：SKILL.md 在根目录、标准目录
- 修复渐进加载：核心在 L2、详情在 L3

**验证流程**：
1. 对每个建议的修复，问："如果移除这个修复，AI 还会基于现有内容产生正确输出吗？"
2. 如果是 → 修复不必要，丢弃它
3. 如果否 → 验证修复使用最小干预（优先 MODIFY 而非 ADD）
4. **验证修复匹配适用标准**

**如果任何检查失败 → 修改或丢弃修复建议**

---

## 步骤 7B：引用回查验证（强制）

<citation_backcheck_verification>
**关键**：此步骤防止审计报告中出现"幻觉"——引用不存在的内容或错误的行号。

**执行时机**：在步骤 7 完成后、步骤 8 生成报告前执行。

**验证流程**：

对于每一个已确认的 🔴/🟡 问题：

1. **重新读取源文件**：
   - 使用 Read 工具读取问题所在的文件
   - 定位到问题声称的行号

2. **验证内容匹配**：
   - 检查该行的实际内容是否与问题描述一致
   - 检查问题中引用的"当前内容"是否确实存在于文件中

3. **验证行号准确**：
   - 确认行号是精确的，而非估计值
   - 如果内容存在但行号不准确，修正行号

**验证结果处理**：

| 验证结果 | 处理方式 |
|----------|----------|
| 内容和行号都匹配 | ✅ 保留问题 |
| 内容存在但行号错误 | 🔧 修正行号后保留 |
| 内容不存在 | ❌ **删除该问题** |
| 部分内容匹配 | 🔧 修正引用内容后保留 |

**必须输出**（内部检查点，不显示给用户）：
```
引用验证: 验证了 N 个问题, 通过 M 个, 修正 K 个, 删除 L 个
```

**如果删除了问题**：
- 从已确认问题列表中移除
- 更新问题统计数字
- 记录删除原因（供调试）

**禁止行为**：
- 禁止跳过此步骤
- 禁止在发现内容不存在后仍保留该问题
- 禁止使用"可能在附近"等模糊描述代替精确验证
</citation_backcheck_verification>

---

## 步骤 8：生成报告

按照 `ref-output-format.md` 的结构。

**第 2 节交叉分析必须包含：**
- 命名与编号：带具体发现的实际检查结果
- 目录-内容匹配：比较结果
- 引用完整性：列出断链引用
- （对于多文件）设计一致性、渐进加载结果

**第 3 节问题清单必须包含：**
- 验证统计："扫描 X → 验证 Y → 过滤 Z"
- 已确认和已过滤问题，附过滤原因

<output_language_check>
输出前：验证所有自然语言文本使用 {OUTPUT_LANGUAGE}。
ref-output-format.md 中的模板是结构参考，不是要复制的文本。
</output_language_check>

---

## 步骤 8B：保存报告到文件（必须）

<report_save_execution>
**生成审计报告内容后，使用 scripts/save_report.py 保存到文件：**

1. **确定保存参数**：
   - 目录审计：`project_name` = 目录名，`output_dir` = 父目录
   - 文件审计：`project_name` = 文件名（无扩展名），`output_dir` = 文件目录
   - 粘贴文本：`project_name` = `inline_text`，`output_dir` = 当前工作目录

2. **运行保存脚本**（跨平台）：
   ```bash
   # Windows：
   python -X utf8 scripts/save_report.py --project "{project_name}" --output-dir "{output_dir}" --content "{report_content}"

   # macOS/Linux：
   python3 scripts/save_report.py --project "{project_name}" --output-dir "{output_dir}" --content "{report_content}"
   ```
   **跨平台注意事项**：
   - Windows：使用 `python -X utf8` 以支持中文
   - macOS/Linux：使用 `python3`，UTF-8 为默认
   - 所有平台：所有路径用 `"` 引号包裹以兼容中文/空格

3. **捕获输出**：脚本将保存的文件路径输出到 stdout

4. **备用策略**（如脚本失败或无输出）：
   - 使用 CLI 内置文件写入能力保存报告
   - 相同文件名格式：`审计报告_{project}_{YYYYMMDD_HHmmss}.md`
   - 相同输出目录规则
   - 如所有写入方法都失败，在终端显示完整报告作为最后手段

5. **终端输出**（仅简要摘要）：
   ```
   审计完成: 🔴{n} 🟡{n} 🟢{n} | 判定: {通过/需改进/不通过}
   审计报告已保存至: {full_path}

   请查看报告后输入要修复的问题编号:
   - 输入 1 或 1,2 或 1-3 选择修复项
   - 输入 all 应用所有修复
   - 输入其他内容继续对话
   ```
</report_save_execution>

---

## 步骤 9：等待用户确认（阶段门）

> **关键**：第 5 节必须在停止前输出"建议操作"表格。不要跳过此表格。

**第 5 节必需输出（按顺序）：**
1. 验证统计、质量判定、整体判定
2. **建议操作表格**（必须 - 不要跳过）：
   - 待修复问题表格，带问题编号和章节引用
   - 待优化问题表格（如有 🟢 问题）
   - 操作选项说明
3. **停止** - 等待用户选择要应用的修复
4. 只有在用户确认后（如"1"、"1,2"、"all"）→ 应用选定的修复
5. 如用户未选择 → 不做任何操作，等待

**修复执行原则（关键）：**
应用修复时，记住：AI 执行者有上下文理解能力。优先 MODIFY/DELETE 而非 ADD。不要在 AI 能从上下文推断的地方添加禁止或硬编码值。写入前根据步骤 7 检查重新验证每个修复。
